{"cells":[{"cell_type":"markdown","metadata":{},"source":["Importing the required modules"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"]},{"cell_type":"markdown","metadata":{},"source":["Preparing the data using ImageDataGenerator class, we have also increased the training data using Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_data(train_data_dir, target_size=(100, 100), batch_size=128, validation_split=0.2):\n","    # Data augmentation to increase diversity of training data\n","    train_datagen = ImageDataGenerator(\n","        rescale=1.0 / 255,  # Rescale pixel values to range [0,1]\n","        validation_split=validation_split,  # Split data into training and validation sets\n","        rotation_range=20,  # Rotate images randomly up to 20 degrees\n","        width_shift_range=0.2,  # Shift images horizontally up to 20% of the width\n","        height_shift_range=0.2,  # Shift images vertically up to 20% of the height\n","        shear_range=0.2,  # Shear transformation with max intensity of 20%\n","        zoom_range=0.2,  # Randomly zoom images up to 20%\n","        horizontal_flip=True  # Randomly flip images horizontally\n","    )\n","    \n","    # Generate batches of augmented data from the directory\n","    train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        subset='training'\n","    )\n","    \n","    validation_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        subset='validation'\n","    )\n","    \n","    return train_generator, validation_generator\n"]},{"cell_type":"markdown","metadata":{},"source":["Creating our model on top of the GlobalAveragePooling2D pre trained model\n"]},{"cell_type":"markdown","metadata":{},"source":["We add the final fully connected layer and add a dropout of 50% to reduce overfitting\n"]},{"cell_type":"markdown","metadata":{},"source":["There are 10 classes of the images\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_model(input_shape=(100, 100, 3), num_classes=10):\n","    # Load pre-trained MobileNetV2 model without the top classification layer\n","    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False  # Freeze the weights of the base model\n","    \n","    # Build a sequential model by adding layers\n","    model = Sequential([\n","        base_model,  # Use the MobileNetV2 base model\n","        GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n","        Dropout(0.5),  # Dropout layer with dropout rate of 0.5 to prevent overfitting\n","        Dense(1024, activation='relu'),  # Fully connected layer with 1024 units and ReLU activation\n","        Dense(num_classes, activation='softmax')  # Output layer with num_classes units and softmax activation\n","    ])\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compile_model(model):\n","    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"markdown","metadata":{},"source":["| Layer (type)                | Output Shape     | Param #    |\n","|-----------------------------|------------------|------------|\n","| mobilenetv2_1.00_100        | (None, 3, 3, 1280)| 2,257,984  |\n","| GlobalAveragePooling2D      | (None, 1280)     | 0          |\n","| dropout                     | (None, 1280)     | 0          |\n","| dense                       | (None, 1024)     | 1,311,744  |\n","| dense_1                     | (None, 10)       | 10,250     |\n"]},{"cell_type":"markdown","metadata":{},"source":["Total params: 3,583,978\n","Trainable params: 1,321,994\n","Non-trainable params: 2,261,984\n"]},{"cell_type":"markdown","metadata":{},"source":["To plot the confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_confusion_matrix(conf_matrix, class_names):\n","    # Plotting the confusion matrix\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Main Function of the code that runs the functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def main():\n","    # Define directories and parameters\n","    train_data_dir = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\" #For running on the Kaggle Kernel\n","    target_size = (100, 100)\n","    batch_size = 128\n","    validation_split = 0.2\n","    num_classes = 10\n","    epochs = 10 #Gives an accuracy of about 70% whereas epochs=20 causes overfitting and goes below 10%\n","    \n","    # Prepare data\n","    train_generator, validation_generator = prepare_data(train_data_dir, target_size=target_size, batch_size=batch_size, validation_split=validation_split)\n","    \n","    # Create model\n","    model = create_model(input_shape=(target_size[0], target_size[1], 3), num_classes=num_classes)\n","    \n","    # Compile model\n","    compile_model(model)\n","    \n","    # Early stopping callback to prevent overfitting\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","    \n","    # Train the model\n","    model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[early_stopping])\n","    \n","    # Make predictions on the validation set\n","    predictions = model.predict(validation_generator)\n","    y_pred = np.argmax(predictions, axis=1)  # Get the index of the highest probability as predicted class\n","    \n","    # Get true labels from the generator\n","    y_true = validation_generator.classes  # True labels are encoded as integers based on class indices\n","    \n","    # Compute confusion matrix\n","    conf_matrix = confusion_matrix(y_true, y_pred)\n","    \n","    # Plot the confusion matrix\n","    class_names = list(validation_generator.class_indices.keys())  # Extract class names from the generator\n","    plot_confusion_matrix(conf_matrix, class_names)\n","    \n","    # Check accuracy to verify the model's performance\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f\"Validation Accuracy: {accuracy}\")\n","\n","# Call the main function\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":868335,"sourceId":5048,"sourceType":"competition"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
